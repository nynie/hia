

*“AI doesn't have to be evil to destroy humanity – if AI has a goal and humanity
just happens in the way, it will destroy humanity as a matter of course without
even thinking about it, no hard feelings." – Elon Musk*

The term 'artificial intelligence' is described as the theory and development of computer systems able to perform tasks normally requiring human intelligence, such as visual perception, speech recognition, decision-making, and translation between languages. In other words, AI can do anything a human can -- just without the humanity. Now, what exactly is humanity? In the dictionary, it can be taken as two meanings, 'all of human beings collectively'; and, 'the quality of humane; benevolence'. Having taken these into account, if AI lack empathy and morality - can they really be considered evil? Even through something so inexplicably paramount as the eradication of the human race.
Considering this, if AI cannot be reasonably called 'evil', can they be called kind? Behind every algorithm there is a programmer. The main goal of AI is to improve the lives of humans and make further and faster advancements into technology. If there is to be a point where an AI develops so much so that it begins to surpass the need for human configuration, then it poses a possibility that it becomes its own individual person, a human-like entity whose system can no longer be regulated or controlled as once before. The progression of this may even lead to an ultimate status of sentience within the program; to which I personally believe is when the concept of morality and ethics starts to apply to it.

It is not so far-fetched to propose the idea that one day AI advancement may lead to the eradication of humanity simply just through outlasting them: a robot could perhaps end up as an immortal being if repairs are regularly made. In a documentary, Musk warns that 'AI could create an immortal dictator of which we can never escape'- a permanent dictator who maintains oppression forever. The only true way to combat this would be to fuse humanity with robotics themselves - a topic more notably known as 'cybernetic enhancements' or, rather, 'cyborgs'. Through the mechanical replacement of a person's anatomy, we could create unnatural progressions and optimizations which would typically otherwise take millions of years through natural evolution. However, the act of this itself also brings forth many more ethical debates. How many mechanical additions to a human body until it is no longer cyborg, but full robot? This itself is similar to the 'Ship of Theseus' thought experiment that raises the question of whether an object that has had all of its components replaced remains fundamentally the same object. And can a fully-transformed cyborg then commit evil acts? Would it still be considered evil, or simply just protocol?

I believe that emotions are the biggest factor in what makes us human. The ability to feel empathy for others; to forgive; to trust; to honour. If an AI has yet to reach a point where it cannot functin entirely on its own, with all the same fundamentals as that of a human, it cannot be evil. It's just doing it's job.
